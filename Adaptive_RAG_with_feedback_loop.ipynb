{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W0lhTDKvVQU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from typing import List, Dict, Tuple\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "hRMRemAtvWGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorStore:\n",
        "    def __init__(self):\n",
        "        self.documents = []\n",
        "        self.embeddings = []\n",
        "\n",
        "    def add_document(self, doc: str, embedding: np.ndarray):\n",
        "        self.documents.append(doc)\n",
        "        self.embeddings.append(embedding)\n",
        "\n",
        "    def retrieve(self, query_embedding: np.ndarray, k: int = 3) -> List[Tuple[str, float]]:\n",
        "        # Simple cosine similarity for retrieval\n",
        "        similarities = [\n",
        "            np.dot(query_embedding, emb) / (np.linalg.norm(query_embedding) * np.linalg.norm(emb))\n",
        "            for emb in self.embeddings\n",
        "        ]\n",
        "        # Get top k documents\n",
        "        top_k_indices = np.argsort(similarities)[-k:][::-1]\n",
        "        return [(self.documents[i], similarities[i]) for i in top_k_indices]"
      ],
      "metadata": {
        "id": "SDghHgRcvarz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedbackStore:\n",
        "    def __init__(self):\n",
        "        self.feedback_data = []\n",
        "\n",
        "    def store_feedback(self, query: str, response: str, feedback: Dict):\n",
        "        self.feedback_data.append({\n",
        "            'query': query,\n",
        "            'response': response,\n",
        "            'feedback': feedback\n",
        "        })\n",
        "\n",
        "    def get_relevant_feedback(self, query: str) -> List[Dict]:\n",
        "        # Simple relevance check based on query similarity\n",
        "        return [fb for fb in self.feedback_data if query.lower() in fb['query'].lower()]"
      ],
      "metadata": {
        "id": "ybuoN5hjvdBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaptiveRAG:\n",
        "    def __init__(self):\n",
        "        self.vector_store = VectorStore()\n",
        "        self.feedback_store = FeedbackStore()\n",
        "        self.knowledge_base = [\n",
        "            \"Python is a versatile programming language used for web development and data science.\",\n",
        "            \"Machine learning is a subset of artificial intelligence that focuses on building systems that learn from data.\",\n",
        "            \"RAG combines retrieval and generation for better context-aware responses.\"\n",
        "        ]\n",
        "        # Initialize vector store with dummy embeddings\n",
        "        for doc in self.knowledge_base:\n",
        "            self.vector_store.add_document(doc, np.random.rand(100))\n",
        "\n",
        "    def generate_embedding(self, text: str) -> np.ndarray:\n",
        "        # Simulate embedding generation (in practice, use a model like BERT)\n",
        "        return np.random.rand(100)\n",
        "\n",
        "    def generate_response(self, query: str, context: List[str]) -> str:\n",
        "        # Simulate LLM response generation\n",
        "        context_str = \"\\n\".join(context)\n",
        "        return f\"Based on the context:\\n{context_str}\\n\\nAnswer: {query}\"\n",
        "\n",
        "    def refine_response(self, query: str, initial_response: str, feedback: Dict) -> str:\n",
        "        # Refine response based on feedback\n",
        "        if feedback.get('is_correct', False):\n",
        "            return initial_response\n",
        "        else:\n",
        "            # Apply simple refinement based on feedback\n",
        "            correction = feedback.get('correction', '')\n",
        "            return f\"{initial_response}\\nRefined with feedback: {correction}\"\n",
        "\n",
        "    def process_query(self, query: str, feedback: Dict = None) -> Tuple[str, List[str]]:\n",
        "        logger.info(f\"Processing query: {query}\")\n",
        "\n",
        "        # Generate query embedding\n",
        "        query_embedding = self.generate_embedding(query)\n",
        "\n",
        "        # Retrieve relevant documents\n",
        "        retrieved_docs = self.vector_store.retrieve(query_embedding)\n",
        "        context = [doc for doc, _ in retrieved_docs]\n",
        "\n",
        "        # Check for relevant feedback\n",
        "        relevant_feedback = self.feedback_store.get_relevant_feedback(query)\n",
        "        if relevant_feedback:\n",
        "            logger.info(\"Applying previous feedback to refine response\")\n",
        "            context.extend([fb['response'] for fb in relevant_feedback])\n",
        "\n",
        "        # Generate initial response\n",
        "        response = self.generate_response(query, context)\n",
        "\n",
        "        # If feedback is provided, refine the response\n",
        "        if feedback:\n",
        "            response = self.refine_response(query, response, feedback)\n",
        "            self.feedback_store.store_feedback(query, response, feedback)\n",
        "\n",
        "        return response, context"
      ],
      "metadata": {
        "id": "sR1s6vNMvfcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Initialize Adaptive RAG system\n",
        "    rag = AdaptiveRAG()\n",
        "\n",
        "    query = \"What is Python used for?\"\n",
        "\n",
        "    # First query without feedback\n",
        "    response, context = rag.process_query(query)\n",
        "    print(\"Initial Response:\")\n",
        "    print(response)\n",
        "\n",
        "    # Simulate user feedback\n",
        "    feedback = {\n",
        "        'is_correct': False,\n",
        "        'correction': 'Python is also used for automation and scripting.'\n",
        "    }\n",
        "\n",
        "    # Process query with feedback\n",
        "    refined_response, context = rag.process_query(query, feedback)\n",
        "    print(\"\\nRefined Response with Feedback:\")\n",
        "    print(refined_response)"
      ],
      "metadata": {
        "id": "2zFjHBhMviz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmYUfZScvlIr",
        "outputId": "714a16fd-95d9-41a6-b348-67f9a85bf560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Response:\n",
            "Based on the context:\n",
            "RAG combines retrieval and generation for better context-aware responses.\n",
            "Python is a versatile programming language used for web development and data science.\n",
            "Machine learning is a subset of artificial intelligence that focuses on building systems that learn from data.\n",
            "\n",
            "Answer: What is Python used for?\n",
            "\n",
            "Refined Response with Feedback:\n",
            "Based on the context:\n",
            "RAG combines retrieval and generation for better context-aware responses.\n",
            "Machine learning is a subset of artificial intelligence that focuses on building systems that learn from data.\n",
            "Python is a versatile programming language used for web development and data science.\n",
            "\n",
            "Answer: What is Python used for?\n",
            "Refined with feedback: Python is also used for automation and scripting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8WUJEGCOvo8z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}